# üê≥ An√°lisis de Recursos Docker (Total vs. Actual)

### ‚ò¢Ô∏è Comando de Liberaci√≥n Total (Un solo paso)
Si deseas borrar **todo rastro** (im√°genes base, vol√∫menes, contenedores y cach√©) y recuperar ~10GB de espacio:
```bash
make nuke
```
*(O directamente: `docker system prune -a -f --volumes`)*

Este documento detalla el consumo de recursos (Disco y RAM) del proyecto **Social Bot Scheduler**.
 Se ha ajustado para reflejar la diferencia entre el estado actual de tu entorno y el potencial total del repositorio para que reclutadores y novatos tomen decisiones informadas.

## üèÅ Estado del Entorno Docker

> [!WARNING]
> Tu entorno actual puede estar "incompleto" si solo has descargado algunos servicios. Para ejecutar el laboratorio completo, debes considerar el **Tama√±o Real Total**.

### üßπ Gesti√≥n de Recursos y Limpieza
Dada la alta demanda t√©cnica de este repositorio (8 bases de datos simult√°neas), es vital saber c√≥mo liberar recursos:
- Consulta la [Gu√≠a de Recursos Docker](file:///c:/dev/social-bot-scheduler/docs/DOCKER_RESOURCES.md) para ver el reporte de estr√©s y l√≠mites.
- Usa `make clean` o `python hub.py clean` para una limpieza est√°ndar.
- Usa `docker system prune -a -f --volumes` para una limpieza total (Deep Cleanup).

Este documento detalla el consumo de recursos (Disco y RAM) del proyecto **Social Bot Scheduler**. Se ha ajustado para reflejar la diferencia entre el estado actual de tu entorno y el potencial total del repositorio para que reclutadores y novatos tomen decisiones informadas.

## üèÅ Estado del Entorno Docker

> [!WARNING]
> Tu entorno actual puede estar "incompleto" si solo has descargado algunos servicios. Para ejecutar el laboratorio completo, debes considerar el **Tama√±o Real Total**.

| Escenario | Almacenamiento (Disco) | RAM Sugerida | Notas |
|-----------|------------------------|--------------|-------|
| **Estado Parcial** | Variable (~600 MB - 1 GB) | 4 GB | Solo servicios b√°sicos o un caso individual. |
| **Repositorio Total** | **~8.0 GB** | **16 GB** | Los 18+ servicios, 8 bases de datos y herramientas de observabilidad. |

---

## üèóÔ∏è Desglose Exhaustivo de Almacenamiento (Potential)

Si decides hacer un `docker-compose --profile full pull`, este es el impacto en disco:

### üñºÔ∏è Im√°genes (Total: ~6.8 GB)
| Categor√≠a | Im√°genes | Tama√±o Est. |
|-----------|----------|-------------|
| **Orquestaci√≥n** | n8n (v2.7.5) | 580 MB |
| **Bases de Datos Pesadas** | MSSQL (2022) + Cassandra (4.1) | 2.8 GB |
| **Bases de Datos Medias** | MySQL, MariaDB, MongoDB, Postgres | 2.0 GB |
| **Observabilidad** | Prometheus, Grafana, cAdvisor | 650 MB |
| **Microservicios (Destinos)** | PHP, Alpine, Node, Python, Ruby, Go | 800 MB |

### üíæ Vol√∫menes y Persistencia (Total: ~1.2 GB)
- **Cach√© de Construcci√≥n**: ~500 MB (Capas intermedias de Dockerfiles personalizados).
- **Datos de DBs**: ~500 MB (Espacio reservado para persistencia de los 8 motores).
- **Configuraci√≥n**: ~200 MB (Logs, n8n workflows, grafana dashboards).

---

## üö¶ Decisi√≥n de Implementaci√≥n: ¬øTodo o Caso a Caso?

Para usuarios con recursos limitados, recomendamos la **Activaci√≥n por Perfiles** (`profiles`):

1.  **Novato (Ligero)**: `docker-compose --profile case01 up -d`
    *   *Consumo*: ~1.2 GB Disco / 1.5 GB RAM Total.
2.  **Reclutador (Est√°ndar)**: Casos 01 al 06.
    *   *Consumo*: ~4.0 GB Disco / 8 GB RAM.
3.  **Senior (Full Lab)**: Todos los casos + Infraestructura.
    *   *Consumo*: ~8.0 GB Disco / 16 GB RAM.

---

## üèÅ Reporte de Prueba de Estr√©s (Stress Test - Feb 2026)

Se realiz√≥ una ejecuci√≥n del stack completo (`--profile full`) en el hardware actual, resultando en los siguientes hallazgos cr√≠ticos:

| Hallazgo | Impacto | Causa Ra√≠z |
| :--- | :--- | :--- |
| **Estabilidad General** | **17/20 Servicios OK** | Los servicios clave (n8n, Dashboard, DBs ligeras) operan sin problemas. |
| **Falla en Cassandra** | **Cerrado Forzoso (OOM)** | Alcanz√≥ el l√≠mite de 2GB de RAM configurado, provocando un exit (137). |
| **Falla en Case 07/08** | **Inestabilidad en Ruby/Flask** | Al caer Cassandra y subir el consumo general, los emisores/receptores dependientes fallaron. |
| **Consumo de Disco** | **~8.5 GB** | Incluye im√°genes descargadas y capas de construcci√≥n de Dockerfiles. |

> [!IMPORTANT]
> **Conclusi√≥n**: El hardware actual es ideal para el **Perfil √ìptimo** (Casos 01-06). Para el **Perfil Experto** (Todo el repo), se recomienda una m√°quina con al menos 16-24 GB de RAM (ej: Mac Mini con Silicon) para evitar la ca√≠da de servicios pesados como Cassandra.

---

## üßπ Limpieza y Liberaci√≥n de Recursos

Antes de apagar el sistema o migrar de m√°quina, es fundamental limpiar los recursos para devolver el disco y la memoria al sistema operativo.

### Opci√≥n 1: V√≠a Makefile (Recomendado)
```bash
make clean
```

### Opci√≥n 2: V√≠a HUB CLI
```bash
python hub.py clean
```

### Opci√≥n 3: Limpieza Total (Deep Cleanup)
Si deseas liberar **todo** el espacio (incluyendo im√°genes base como MSSQL, Cassandra y PHP) para que la m√°quina quede como si nunca hubiera ejecutado el repo:

```bash
# ADVERTENCIA: Esto borrar√° todas las im√°genes no usadas por otros contenedores activos
docker system prune -a -f --volumes
```

### ¬øQu√© hace este proceso?
1.  **Detiene y elimina** todos los contenedores del proyecto.
2.  **Elimina los vol√∫menes** (borrando todos los datos de las bases de datos).
3.  **Limpia im√°genes hu√©rfanas** y redes temporales.
4.  **Prune -a**: Elimina im√°genes base, liberando hasta 10GB+ de espacio.
